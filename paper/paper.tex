\documentclass[showpacs,showkeys,10pt,onecolumn,superscriptaddress,notitlepage]{revtex4-1}

\usepackage[ansinew]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{float}

\usepackage{amsmath,amsthm,amssymb,amscd}
\usepackage{bbm}
\usepackage{mathtools}
\usepackage{hyperref}

\bibliographystyle{plain}

\newcommand{\Epi}{\affiliation{Department of Epileptology, University of Bonn, Venusberg Campus 1, 53127~Bonn, Germany}}
\newcommand{\HISKP}{\affiliation{Helmholtz Institute for Radiation and Nuclear Physics, University of Bonn, Nussallee~14--16, 53115~Bonn, Germany}}
\newcommand{\THP}{\affiliation{Institute for Theoretical Physics, University of Cologne, 50937 K\"oln, Germany}}
\newcommand{\FZJ}{\affiliation{Forschungszentrum J\"ulich, Institute for Energy and Climate Research - Systems Analysis and Technology Evaluation (IEK-STE), 52428 J\"ulich, Germany}}
\newcommand{\Bethe}{\affiliation{Physikalisches Institut and Bethe Center for Theoretical Physics, Universit\"at Bonn, Nussallee 12, 53115 Bonn, Germany}}


\frenchspacing

\begin{abstract}
    This python library allows the numerical calculation of Kramers--Moyal coefficients for stochastic data of any dimension and for any desired order.
    The library relies on a kernel-based estimation to obtain accurate results for data with a low number of data points, employing a convolution schema to circumvent the traditional drawbacks of binning data, which is especially helpful for larger datasets.
    The flexibility of the code allows the calculation of the Kramers--Moyal coefficients for data of any dimension, up to any order, without additional parameters, while including a handful of kernels for the estimation, up to user's choice.
\end{abstract}

\begin{document}

\title{Python KM: Kramers--Moyal coefficients for stochastic processes}


\author{Leonardo~Rydin~Gorj\~ao}
\email[Electronic mail: ]{l.rydin.gorjao@fz-juelich.de}
\Epi \HISKP \THP \FZJ

\author{Francisco Meirinhos}
\email[Electronic mail: ]{meirinhos@physik.uni-bonn.de}
\Bethe

\keywords{Kramers--Moyal coefficents, N-dimensional stochastic processes, Markovian processes, Master equation, Fokker--Planck equation, Ornstein--Uhlenbeck process, Python}

\maketitle

\textbf{Library available at}:  \texttt{\href{https://github.com/LRydin/KramersMoyal}{github.com/LRydin/KramersMoyal}}

\section{Summary}

A general problem for evaluating Markovian stochastic processes is the retrieval of the moments or the Kramers--Moyal coefficients $\mathcal{M}$ from data or time-series.
The Kramers--Moyal coefficients are derived from an Taylor expansion of the master equation that describes the probability evolution of a Markovian stochastic process.

Given a set of stochastic data, ergodic or quasi-stationary, the extensive literature of stochastic processes awards a set of measures, such as the Kramers--Moyal coefficients or its moments, which link stochastic processes to a probabilistic description of the process or of the family of processes \cite{Risken}.
Most commonly known is the Fokker--Planck equation or truncated forward Kolmogorov equation, partial differential equations, obtained from the Taylor expansion of the master equation.



Of particular relevance is the growing evidence that real-world data displays higher-order ($n>2$) Kramers--Moyal coefficients, which has a two-fold consequence: The common truncation at third order of the forward Kolmogorov equation, giving rise to the Fokker--Planck equation, is no longer valid.
The evidence of higher-order ($n>2$) Kramers--Moyal coefficients in recorded data thus invalidates the aforementioned common argument for truncation, based on Pawula's theorem and thus rendering the Fokker--Planck description unjustified \cite{Tabar}.
A clear and common example is the presence of discontinuous jumps in data\cite{Anvari,Sahalia}, which can give rise to higher-order Kramers--Moyal coefficients, and are evidenced in \cite{Rydin} and references within.


Calculating the moments or Kramers--Moyal coefficients strickly from data can be computationally heavy for long data series and is prone to be innacurate especially where the density of data points is scarce, e.g. usually at the boundaries on the domain of the process.
The most straightforward approach is to perform a histogram-based estimation to evaluate the moments of the system at hand.
This has two main drawbacks: it requires a discrete space of examination of the process, and is shown to be less accurate than using kernel-based estimators \cite{Lamouroux}.

This library is based on a kernel-based estimation, which allows for more robust results given both a wider range of possible kernel shapes to perform the calculation, as well as retrieving the results in a non-binned coordinate space, unlike histogram regressions \cite{Silverman}.
It further employs a convolution of the series in studied with the selected kernel, circumventing the computational issue of sequential array summation, the most common bottleneck in integration time and computer memory.

The package presented here comprises a manifold of options: A general open-source toolbox for the calculation of Kramers--Moyal coefficients for any given data series of any dimension and to any order, with a selection of commonly used kernel estimators.


\section{Mathematics}
For a general $N$-dimensional Markovian process $\boldsymbol{x}'(t)\in\mathbb{R}^N$ tke Kramers--Moyal yields all orders of the cumulants of the conditional probability distribution $P(\boldsymbol{x}',t+\Delta T | \boldsymbol{x}, t)$ as \cite{Risken}
\begin{equation}
\mathcal{M}^{\sigma}(\boldsymbol{x},t)=\lim_{\Delta t\to 0}\frac{1}{\Delta t}\int  dx'[\boldsymbol{x}(t)'-\boldsymbol{x}(t)]^\sigma P(\boldsymbol{x}',t+\Delta T | \boldsymbol{x}, t),
\end{equation}
with $[\dots]^\sigma$ a dyadic multiplication, and the power $\sigma$ allowing for a set of powers depending on the dimensionality of the process.

The exact evaluation of the Kramers--Moyal coefficients for discrete or discretised datasets $\boldsymbol{y}(t)$---any human measure of a process is discrete, as well as any computer generated data---is bounded by the timewise limit imposed.
Taking as an example a two-dimensional case with $\boldsymbol{y}(t)=(y_1(t),y_2(t))\in\mathbb{R}^{2}$, the Kramers--Moyal coefficients $\mathcal{M}^{[\ell, m]}\in\mathbb{R}^{2}$ take the form
\begin{equation}
\begin{aligned}
&\mathcal{M}^{[\ell, m]}(x_1,x_2,t)=\lim_{\Delta t\to 0}\!\frac{1}{\Delta t}\int \mathrm{d} y_1 \mathrm{d} y_2 (y_1(t+\Delta t)-x_1(t))^\ell(y_2(t+\Delta t)-x_2(t))^m \cdot P(y_1,y_2; t+\Delta t|x_1,x_2 ; t),
\end{aligned}
\end{equation}
at a certain measure point $(x_1,x_2)$.
The order of the Kramers--Moyal coefficients is given here by the superscripts $\ell$ and $m$.

Theoretically, there are still two details to attend to: Firstly, for non-stationary data, there is and explicity dependence on $t$, but, as the case discussed here, for stationary (or quasi-stationary) data, $P(\boldsymbol{x}',t+\Delta T | \boldsymbol{x}, t) = P(\boldsymbol{x}',\Delta T | \boldsymbol{x})$.
This entails time-independent Kramers--Moyal coefficients $\mathcal{M}^{\sigma}(\boldsymbol{x})$.
Secondly, $\Delta t$ should take the limiting case of $\Delta t \to 0$, but the restriction of any measuring or storing device---or the nature of the observables themselves---permits only time-sampled or discrete recordings.
In the limiting case where $\Delta t$ is equivalent to the minimal sampling rate of the data, the Kramers--Moyal coefficients take the form, in our two-dimensional example, as

\begin{equation}
\begin{aligned}
\mathcal{M}^{[\ell, m]}(x_1, x_2) = \frac{1}{\Delta t} \langle \Delta y_1^{\ell} \Delta y_2^{m} |_{y_1(t)=x_1, y_2(t)=x_2}\rangle,~\mathrm{with}~\Delta y_i =  y_i(t+ \Delta t) - y_i(t).
\end{aligned}\label{eq:3}
\end{equation}
It is straightforward to generalise this to any dimensions.
The relevance and importance of adequate time-sampling was extensively studied and discussed in \cite{Lehnertz}.
Notice here that if the sampling resolution of the process is known, than that is $\Delta t$.

The Kramers--Moyal coefficients exist on an underlying probabilistic space, i.e., there exists a probabilistic measure assigned to the process, stemming from the master equation describing the family of such processes.
The conventional procedure, as mentioned previously, is to utilise a histogram regression of the observed process and retrieve, via approximation or fitting, the Kramers--Moyal coefficient.
The choice of a histogram measure for the Kramers--Moyal coefficient results in an acceptable measure of the probability density functions of the process but requires a new mathematical space (a distribution space).
The employment of a kernel estimation approach, implemented in this library, permits an identical overview without the necessity of a new (discretised) distribution space, given that the equivalent space of the observable can be taken.

Like the histogram approach for the measure of the Kramers--Moyal coefficients, each single measure of the observable $\boldsymbol{y}(t)$ is averaged, with a designed weight, into the distribution space.
The standing difference, in comparison to the histogram approach, is the riddance of a (discrete) binning system.
All points are averaged, in a weighted fashion, into the distribution space---aiding especially in cases where the number of point in a dataset is small---and awarding a continuous measurable space (easier for fitting, for example) \cite{Lamouroux}.


\section{Exemplary one-dimensional Ornstein--Uhlenbeck process}
A one-dimensional Ornstein--Uhlenbeck process $y(t)$ takes the form

\begin{equation}\label{eq:OU}
    d y = - \theta y dt + \sigma d W(t),
\end{equation}
with $\theta$ denoted as the \textit{drift} or mean-reverting term, $\sigma$ the \textit{diffusion} term or stochastic amplitude, and $W(t)$ is a Brownian motion, i.e., a Wiener process.
For this particular example set $\theta = 0.3$ and $\sigma=0.1$.

To be able to test the library and the retrieval on the Kramers--Moyal coefficients, and subsequently recover the drift and diffusion term, one can numerically integrate the process.
For the present case employ a Euler--Maruyama integrator, for simplicity.
There are more reliable and faster integrators, as for example \texttt{JiTCSDE} \cite{Ansmann}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\linewidth]{Fig_1.pdf}
    \caption{Trajectory of \eqref{eq:OU} for $\theta = 0.3$ and $\sigma=0.1$, for a total time of $500$ time units, with a time step of $0.001$, i.e., comprising $5\times10^5$ data points.}\label{fig:1}
\end{figure}

For the present case, with an integration over $500$ time units and with a timestep of $0.001$, which can be seen in Fig.~\ref{fig:1}.
The first and second Kramers--Moyal coefficients are presented in Fig.~\ref{fig:2}, where as well the conventional histogram-based estimation, a non-convolution based kernel estimation, and this library implementing a convolution of the kernel with the terms the right-hand side in \eqref{eq:3}.
An Epanechnikov kernel was chosen for both kernel-based estimations.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\linewidth]{Fig_2.pdf}
    \caption{Comparison of exemplary results of obtaining the Kramers--Moyal coefficients with a histogram-based approach, a conventional kernel-based approach, and the KM library, sequentially left to right, from the numerical integration of \eqref{eq:OU}.
    The top row displays the \textit{drift} coefficient, i.e., the first Kramers--Moyal coefficients.
    The bottom row displays the \textit{diffusion} coefficient, i.e., the second Kramers--Moyal coefficients.
    For the histogram $40$ bins were used, for the conventional kernel and this library a space with $5500$ numerical points were used, with a bandwidth of $0.05$.
    The total number of points of the numerically integrated data is $5\times10^5$.}\label{fig:2}
\end{figure}

\section{Library}
The presented library is comprised of two separate blocks, \texttt{kernels} and \texttt{km}, and is a standalone package for a non-parametric retrieval of Kramers--Moyal coefficients, solely dependent on \texttt{numpy}, \texttt{scipy}, and \texttt{functools}.
The sub-module \texttt{kernels} comprises the kernels for the kernel-based estimation, similarly available in \texttt{sklearn}, and \texttt{km} performs the desired Kramers--Moyal calculations to any desired power \cite{scikitlearn}.

In order compare the computational speed up of the library the aforementioned Ornstein-Uhlenbeck \eqref{eq:OU} was used (with $\theta = 0.3$ and $\sigma=0.1$), and the total time of integration of the process was increased iteratively.
In Fig.~\ref{fig:3} the comparative results of employing a histogram estimation with $200$ bins, a conventional kernel-based regression in a space with $5500$ numerical points, and this library's kernel-convolution method, over similarly $5500$ numerical points.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.45\linewidth]{Fig_3.pdf}
    \caption{Comparison of speed performance of obtaining the Kramers--Moyal coefficients with a histogram-based approach, a conventional kernel-based approach, and the KM library, sequentially left to right, from the numerical integration of \eqref{eq:OU} over increasing number of data points.
    For the histogram $200$ bins were used, for the conventional kernel and this library a space with $5500$ numerical points was used.
    The total number of points of numerical integration was varied between $5\times10^3$ and $5\times10^6$.
    The horizontal line indicates a total of $1$ second.
    Integration performed on a laptop with an Intel Core i5 CPU @$2.20$~GHz (@$2.56$~GHz turbo).}\label{fig:3}
\end{figure}

% \section{Declaration of interest}
% This package is openly available on GitHub at: \texttt{\href{https://github.com/LRydin/KramersMoyal}{github.com/LRydin/KramersMoyal}} and is still in an experimental stage. Comments, remarks, improvements, and reviews are appreciated.
% This article will be submitted to \textit{The Journal of Open Source Software} at: \texttt{\href{https://joss.theoj.org}{joss.theoj.org}} [ISSN: 2475-9066, OCLC number: 971252162].
% The Python library will be maintained always in open-source structure.
% The authors declare no conflict of interest.

\section{Acknowledgements}
L. R. G. and F. M. contributed equally to this project with their respective expertise.
L. R. G. thanks Klaus Lehnertz and M. Reza Rahimi Tabar for all the help in understanding stochastic processes and developing this package, Dirk Witthaut for the support during the process of writing and reviewing, Gerrit Ansmann for the help in understanding python's intricacies, and Marieke Helmich for the text reviews.
L. R. G. gratefully acknowledges support by the Helmholtz Association, via the joint initiative \emph{Energy System 2050 - A Contribution of the Research Field Energy}, the grant No. VH-NG-1025, the scholarship funding from \textit{E.ON Stipendienfonds}, and the STORM project of the Department of Mathematics, University of Oslo, under the supervision of Giulia di Nunno.
F. M. gratefully acknowledges the fund, in part, by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation), project number 277625399 - CRC 185.

\bibliographystyle{unsrt}
\bibliography{bib}


\end{document}
